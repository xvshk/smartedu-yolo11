"""
PySide6 å®æ—¶è¯¾å ‚è¡Œä¸ºæ£€æµ‹åº”ç”¨
æ”¯æŒæ‘„åƒå¤´å’Œè§†é¢‘æ–‡ä»¶æ£€æµ‹ï¼Œä½¿ç”¨ YOLO æ¨¡å‹è¿›è¡Œè¡Œä¸ºè¯†åˆ«
æ£€æµ‹ç»“æœè‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“
"""
import sys
import os
import cv2
import json
import numpy as np
from datetime import datetime
from typing import Optional, Dict, List, Any
from dataclasses import dataclass, asdict
import requests

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, project_root)

from PySide6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QPushButton, QLabel, QComboBox, QSlider, QGroupBox, QFileDialog,
    QTableWidget, QTableWidgetItem, QHeaderView, QSplitter, QFrame,
    QProgressBar, QMessageBox, QSpinBox, QCheckBox, QLineEdit
)
from PySide6.QtCore import Qt, QTimer, Signal, QThread, Slot
from PySide6.QtGui import QImage, QPixmap, QFont, QColor, QPalette

from backend.foundation.config.behavior_config import BehaviorConfig

# è¡Œä¸ºç±»åˆ«é…ç½®
BEHAVIOR_CLASSES = {
    0: {'name': 'handrise', 'cn_name': 'ä¸¾æ‰‹', 'type': 'normal', 'color': (0, 255, 0)},
    2: {'name': 'write', 'cn_name': 'ä¹¦å†™', 'type': 'normal', 'color': (0, 180, 0)},
    3: {'name': 'sleep', 'cn_name': 'ç¡è§‰', 'type': 'warning', 'color': (255, 0, 0)},
    4: {'name': 'stand', 'cn_name': 'ç«™ç«‹', 'type': 'warning', 'color': (128, 128, 128)},
    5: {'name': 'using_electronic_devices', 'cn_name': 'ä½¿ç”¨ç”µå­è®¾å¤‡', 'type': 'warning', 'color': (255, 0, 255)},
    6: {'name': 'talk', 'cn_name': 'äº¤è°ˆ', 'type': 'warning', 'color': (255, 165, 0)},
    7: {'name': 'head_down', 'cn_name': 'ä½å¤´', 'type': 'warning', 'color': (255, 128, 0)},
}

# ç”µå­è®¾å¤‡ç±»åˆ«ï¼ˆCOCOï¼‰
ELECTRONIC_DEVICE_CLASSES = {
    67: 'cell phone',
    63: 'laptop',
}

# åç«¯ API åœ°å€
API_BASE_URL = "http://127.0.0.1:5000/api"


@dataclass
class Detection:
    """æ£€æµ‹ç»“æœ"""
    class_id: int
    class_name: str
    class_name_cn: str
    confidence: float
    bbox: List[float]
    behavior_type: str
    
    def to_dict(self) -> Dict:
        return asdict(self)


# ==================== å»é‡åŠŸèƒ½ç›¸å…³ç±» ====================

@dataclass
class TrackedObject:
    """è¿½è¸ªå¯¹è±¡ - ç”¨äºè·Ÿè¸ªåŒä¸€ç›®æ ‡åœ¨è¿ç»­å¸§ä¹‹é—´çš„ä½ç½®"""
    track_id: int                    # è¿½è¸ªID
    bbox: List[float]                # å½“å‰è¾¹ç•Œæ¡† [x1, y1, x2, y2]
    last_seen_frame: int             # æœ€åå‡ºç°çš„å¸§å·
    behavior_history: List[int]      # è¡Œä¸ºå†å²ï¼ˆclass_idåˆ—è¡¨ï¼Œæœ€è¿‘Nå¸§ï¼‰


@dataclass
class BehaviorState:
    """è¡Œä¸ºçŠ¶æ€ - è®°å½•å•ä¸ªè¿½è¸ªç›®æ ‡çš„è¡Œä¸ºçŠ¶æ€"""
    track_id: int                    # è¿½è¸ªID
    behavior_class_id: int           # å½“å‰è¡Œä¸ºç±»åˆ«ID
    behavior_name: str               # è¡Œä¸ºåç§°
    start_time: datetime             # è¡Œä¸ºå¼€å§‹æ—¶é—´
    last_update_time: datetime       # æœ€åæ›´æ–°æ—¶é—´
    last_record_time: datetime       # æœ€åè®°å½•åˆ°æ•°æ®åº“çš„æ—¶é—´
    bbox: List[float]                # ä½ç½®ä¿¡æ¯
    
    def duration_seconds(self) -> float:
        """è·å–è¡Œä¸ºæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰"""
        return (datetime.now() - self.start_time).total_seconds()
    
    def time_since_last_record(self) -> float:
        """è·å–è·ç¦»ä¸Šæ¬¡è®°å½•çš„æ—¶é—´ï¼ˆç§’ï¼‰"""
        return (datetime.now() - self.last_record_time).total_seconds()


@dataclass
class DeduplicationStats:
    """å»é‡ç»Ÿè®¡"""
    total_detections: int = 0        # æ€»æ£€æµ‹æ¬¡æ•°
    recorded_count: int = 0          # å®é™…è®°å½•æ¬¡æ•°
    skipped_same_behavior: int = 0   # å› ç›¸åŒè¡Œä¸ºè·³è¿‡çš„æ¬¡æ•°
    skipped_cooldown: int = 0        # å› å†·å´æœŸè·³è¿‡çš„æ¬¡æ•°
    
    @property
    def dedup_rate(self) -> float:
        """å»é‡ç‡"""
        if self.total_detections == 0:
            return 0.0
        return (self.total_detections - self.recorded_count) / self.total_detections
    
    def reset(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.total_detections = 0
        self.recorded_count = 0
        self.skipped_same_behavior = 0
        self.skipped_cooldown = 0


from typing import Tuple, Set


class PositionTracker:
    """ä½ç½®è¿½è¸ªå™¨ - è¿½è¸ªæ£€æµ‹ç›®æ ‡åœ¨è¿ç»­å¸§ä¹‹é—´çš„ä½ç½®å¯¹åº”å…³ç³»"""
    
    def __init__(self, iou_threshold: float = 0.5, max_lost_frames: int = 5, max_tracked_objects: int = 100):
        """
        åˆå§‹åŒ–ä½ç½®è¿½è¸ªå™¨
        
        Args:
            iou_threshold: IoUåŒ¹é…é˜ˆå€¼ï¼Œå¤§äºæ­¤å€¼è®¤ä¸ºæ˜¯åŒä¸€ç›®æ ‡
            max_lost_frames: æœ€å¤§ä¸¢å¤±å¸§æ•°ï¼Œè¶…è¿‡åç§»é™¤è¿½è¸ª
            max_tracked_objects: æœ€å¤§è¿½è¸ªå¯¹è±¡æ•°é‡ï¼Œç”¨äºå†…å­˜ä¿æŠ¤
        """
        self.iou_threshold = iou_threshold
        self.max_lost_frames = max_lost_frames
        self.max_tracked_objects = max_tracked_objects
        self.tracked_objects: Dict[int, TrackedObject] = {}
        self.next_track_id = 1
        self.current_frame = 0
    
    def _compute_iou(self, box1: List[float], box2: List[float]) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoUï¼ˆäº¤å¹¶æ¯”ï¼‰
        
        Args:
            box1: ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡† [x1, y1, x2, y2]
            box2: ç¬¬äºŒä¸ªè¾¹ç•Œæ¡† [x1, y1, x2, y2]
            
        Returns:
            IoUå€¼ï¼ŒèŒƒå›´[0, 1]
        """
        try:
            x1_1, y1_1, x2_1, y2_1 = box1
            x1_2, y1_2, x2_2, y2_2 = box2
            
            # ç¡®ä¿åæ ‡æœ‰æ•ˆ
            if x2_1 <= x1_1 or y2_1 <= y1_1 or x2_2 <= x1_2 or y2_2 <= y1_2:
                return 0.0
            
            # è®¡ç®—äº¤é›†åŒºåŸŸ
            inter_x1 = max(x1_1, x1_2)
            inter_y1 = max(y1_1, y1_2)
            inter_x2 = min(x2_1, x2_2)
            inter_y2 = min(y2_1, y2_2)
            
            # å¦‚æœæ²¡æœ‰äº¤é›†
            if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:
                return 0.0
            
            # è®¡ç®—äº¤é›†é¢ç§¯
            inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
            
            # è®¡ç®—ä¸¤ä¸ªæ¡†çš„é¢ç§¯
            area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
            area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
            
            # è®¡ç®—å¹¶é›†é¢ç§¯
            union_area = area1 + area2 - inter_area
            
            if union_area <= 0:
                return 0.0
            
            # è®¡ç®—IoU
            iou = inter_area / union_area
            return max(0.0, min(1.0, iou))  # ç¡®ä¿åœ¨[0, 1]èŒƒå›´å†…
            
        except Exception as e:
            print(f"IoUè®¡ç®—é”™è¯¯: {e}")
            return 0.0
    
    def _match_detections(self, detections: List[Detection]) -> Dict[int, int]:
        """
        åŒ¹é…æ£€æµ‹ç»“æœä¸å·²è¿½è¸ªå¯¹è±¡
        
        Args:
            detections: å½“å‰å¸§çš„æ£€æµ‹ç»“æœåˆ—è¡¨
            
        Returns:
            Dict mapping detection index to track_id
        """
        matches = {}
        used_track_ids = set()
        
        if not self.tracked_objects or not detections:
            return matches
        
        # è®¡ç®—æ‰€æœ‰æ£€æµ‹ä¸è¿½è¸ªå¯¹è±¡ä¹‹é—´çš„IoU
        iou_matrix = []
        for det_idx, det in enumerate(detections):
            row = []
            for track_id, tracked in self.tracked_objects.items():
                iou = self._compute_iou(det.bbox, tracked.bbox)
                row.append((iou, track_id))
            iou_matrix.append(row)
        
        # è´ªå©ªåŒ¹é…ï¼šæŒ‰IoUä»é«˜åˆ°ä½åŒ¹é…
        for det_idx, row in enumerate(iou_matrix):
            # æŒ‰IoUé™åºæ’åº
            sorted_matches = sorted(row, key=lambda x: x[0], reverse=True)
            
            for iou, track_id in sorted_matches:
                if iou >= self.iou_threshold and track_id not in used_track_ids:
                    matches[det_idx] = track_id
                    used_track_ids.add(track_id)
                    break
        
        return matches
    
    def _cleanup_lost_tracks(self):
        """æ¸…ç†ä¸¢å¤±çš„è¿½è¸ªå¯¹è±¡ï¼ˆè¶…è¿‡max_lost_frameså¸§æœªå‡ºç°ï¼‰"""
        lost_ids = []
        for track_id, tracked in self.tracked_objects.items():
            if self.current_frame - tracked.last_seen_frame > self.max_lost_frames:
                lost_ids.append(track_id)
        
        for track_id in lost_ids:
            del self.tracked_objects[track_id]
    
    def _enforce_memory_limit(self):
        """å¼ºåˆ¶å†…å­˜é™åˆ¶ï¼Œç§»é™¤æœ€æ—§çš„è¿½è¸ªå¯¹è±¡"""
        if len(self.tracked_objects) > self.max_tracked_objects:
            # æŒ‰æœ€åå‡ºç°å¸§å·æ’åºï¼Œç§»é™¤æœ€æ—§çš„
            sorted_tracks = sorted(
                self.tracked_objects.items(),
                key=lambda x: x[1].last_seen_frame
            )
            
            # ç§»é™¤è¶…å‡ºé™åˆ¶çš„å¯¹è±¡
            num_to_remove = len(self.tracked_objects) - self.max_tracked_objects
            for i in range(num_to_remove):
                track_id = sorted_tracks[i][0]
                del self.tracked_objects[track_id]
                print(f"å†…å­˜ä¿æŠ¤ï¼šç§»é™¤è¿½è¸ªå¯¹è±¡ {track_id}")
    
    def update(self, detections: List[Detection]) -> List[Tuple[int, Detection]]:
        """
        æ›´æ–°è¿½è¸ªçŠ¶æ€
        
        Args:
            detections: å½“å‰å¸§çš„æ£€æµ‹ç»“æœ
            
        Returns:
            List of (track_id, detection) tuples
        """
        self.current_frame += 1
        result = []
        
        # åŒ¹é…æ£€æµ‹ç»“æœä¸å·²è¿½è¸ªå¯¹è±¡
        matches = self._match_detections(detections)
        
        for det_idx, det in enumerate(detections):
            if det_idx in matches:
                # åŒ¹é…åˆ°å·²æœ‰è¿½è¸ªå¯¹è±¡
                track_id = matches[det_idx]
                tracked = self.tracked_objects[track_id]
                
                # æ›´æ–°è¿½è¸ªå¯¹è±¡
                tracked.bbox = det.bbox
                tracked.last_seen_frame = self.current_frame
                tracked.behavior_history.append(det.class_id)
                # åªä¿ç•™æœ€è¿‘10å¸§çš„è¡Œä¸ºå†å²
                if len(tracked.behavior_history) > 10:
                    tracked.behavior_history = tracked.behavior_history[-10:]
                
                result.append((track_id, det))
            else:
                # æ–°ç›®æ ‡ï¼Œåˆ†é…æ–°çš„è¿½è¸ªID
                track_id = self.next_track_id
                self.next_track_id += 1
                
                self.tracked_objects[track_id] = TrackedObject(
                    track_id=track_id,
                    bbox=det.bbox,
                    last_seen_frame=self.current_frame,
                    behavior_history=[det.class_id]
                )
                
                result.append((track_id, det))
        
        # æ¸…ç†ä¸¢å¤±çš„è¿½è¸ªå¯¹è±¡
        self._cleanup_lost_tracks()
        
        # å¼ºåˆ¶å†…å­˜é™åˆ¶
        self._enforce_memory_limit()
        
        return result
    
    def reset(self):
        """é‡ç½®è¿½è¸ªå™¨çŠ¶æ€"""
        self.tracked_objects.clear()
        self.next_track_id = 1
        self.current_frame = 0


class DeduplicationEngine:
    """å»é‡å¼•æ“ - è´Ÿè´£å†³å®šæ˜¯å¦åº”è¯¥è®°å½•è¡Œä¸º"""
    
    # é»˜è®¤çš„è¡Œä¸ºå†·å´æœŸé…ç½®ï¼ˆç§’ï¼‰
    DEFAULT_BEHAVIOR_COOLDOWNS = {
        3: 30.0,   # ç¡è§‰ - 30ç§’å†·å´
        7: 30.0,   # ä½å¤´ - 30ç§’å†·å´
        5: 45.0,   # ä½¿ç”¨ç”µå­è®¾å¤‡ - 45ç§’å†·å´
        6: 45.0,   # äº¤è°ˆ - 45ç§’å†·å´
    }
    
    def __init__(self, default_cooldown: float = 60.0):
        """
        åˆå§‹åŒ–å»é‡å¼•æ“
        
        Args:
            default_cooldown: é»˜è®¤å†·å´æœŸï¼ˆç§’ï¼‰
        """
        self.default_cooldown = default_cooldown
        self.behavior_cooldowns: Dict[int, float] = dict(self.DEFAULT_BEHAVIOR_COOLDOWNS)
        self.behavior_states: Dict[int, BehaviorState] = {}  # track_id -> BehaviorState
        self.stats = DeduplicationStats()
    
    def set_cooldown(self, behavior_class_id: int, cooldown: float):
        """è®¾ç½®ç‰¹å®šè¡Œä¸ºçš„å†·å´æœŸ"""
        self.behavior_cooldowns[behavior_class_id] = cooldown
    
    def set_default_cooldown(self, cooldown: float):
        """è®¾ç½®é»˜è®¤å†·å´æœŸ"""
        self.default_cooldown = cooldown
    
    def get_cooldown(self, behavior_class_id: int) -> float:
        """è·å–ç‰¹å®šè¡Œä¸ºçš„å†·å´æœŸ"""
        return self.behavior_cooldowns.get(behavior_class_id, self.default_cooldown)
    
    def should_record(self, track_id: int, detection: Detection) -> Tuple[bool, Optional[str]]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è®°å½•è¯¥è¡Œä¸º
        
        Args:
            track_id: è¿½è¸ªID
            detection: æ£€æµ‹ç»“æœ
            
        Returns:
            (should_record, reason) - æ˜¯å¦è®°å½•åŠåŸå› 
        """
        self.stats.total_detections += 1
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¯¥è¿½è¸ªç›®æ ‡çš„å†å²çŠ¶æ€
        if track_id not in self.behavior_states:
            # æ–°ç›®æ ‡ï¼Œåº”è¯¥è®°å½•
            self.stats.recorded_count += 1
            return True, "new_target"
        
        state = self.behavior_states[track_id]
        
        # æ£€æŸ¥è¡Œä¸ºæ˜¯å¦å‘ç”Ÿå˜åŒ–
        if detection.class_id != state.behavior_class_id:
            # è¡Œä¸ºå˜åŒ–ï¼Œåº”è¯¥è®°å½•
            self.stats.recorded_count += 1
            return True, "behavior_changed"
        
        # ç›¸åŒè¡Œä¸ºï¼Œæ£€æŸ¥å†·å´æœŸ
        cooldown = self.get_cooldown(detection.class_id)
        time_since_record = state.time_since_last_record()
        
        if time_since_record >= cooldown:
            # è¶…è¿‡å†·å´æœŸï¼Œåº”è¯¥è®°å½•
            self.stats.recorded_count += 1
            return True, "cooldown_expired"
        
        # åœ¨å†·å´æœŸå†…ï¼Œè·³è¿‡è®°å½•
        self.stats.skipped_cooldown += 1
        return False, "within_cooldown"
    
    def update_state(self, track_id: int, detection: Detection, recorded: bool):
        """
        æ›´æ–°è¡Œä¸ºçŠ¶æ€
        
        Args:
            track_id: è¿½è¸ªID
            detection: æ£€æµ‹ç»“æœ
            recorded: æ˜¯å¦å·²è®°å½•åˆ°æ•°æ®åº“
        """
        now = datetime.now()
        
        if track_id not in self.behavior_states:
            # åˆ›å»ºæ–°çŠ¶æ€
            self.behavior_states[track_id] = BehaviorState(
                track_id=track_id,
                behavior_class_id=detection.class_id,
                behavior_name=detection.class_name_cn,
                start_time=now,
                last_update_time=now,
                last_record_time=now if recorded else now,
                bbox=detection.bbox
            )
        else:
            state = self.behavior_states[track_id]
            
            # æ£€æŸ¥è¡Œä¸ºæ˜¯å¦å˜åŒ–
            if detection.class_id != state.behavior_class_id:
                # è¡Œä¸ºå˜åŒ–ï¼Œé‡ç½®å¼€å§‹æ—¶é—´
                state.behavior_class_id = detection.class_id
                state.behavior_name = detection.class_name_cn
                state.start_time = now
            
            # æ›´æ–°é€šç”¨å­—æ®µ
            state.last_update_time = now
            state.bbox = detection.bbox
            
            if recorded:
                state.last_record_time = now
    
    def cleanup_stale_states(self, active_track_ids: Set[int]):
        """
        æ¸…ç†ä¸å†æ´»è·ƒçš„çŠ¶æ€
        
        Args:
            active_track_ids: å½“å‰æ´»è·ƒçš„è¿½è¸ªIDé›†åˆ
        """
        stale_ids = [
            track_id for track_id in self.behavior_states
            if track_id not in active_track_ids
        ]
        
        for track_id in stale_ids:
            del self.behavior_states[track_id]
    
    def get_stats(self) -> DeduplicationStats:
        """è·å–å»é‡ç»Ÿè®¡"""
        return self.stats
    
    def reset(self):
        """é‡ç½®å»é‡å¼•æ“çŠ¶æ€"""
        self.behavior_states.clear()
        self.stats.reset()


class DetectionThread(QThread):
    """æ£€æµ‹çº¿ç¨‹"""
    frame_ready = Signal(np.ndarray, list)
    fps_updated = Signal(float)
    error_occurred = Signal(str)
    session_created = Signal(int)  # ä¼šè¯ID
    dedup_stats_updated = Signal(object)  # å»é‡ç»Ÿè®¡æ›´æ–°ä¿¡å·
    behavior_recorded = Signal(str)  # è¡Œä¸ºè¢«è®°å½•æ—¶å‘é€ï¼ˆè¡Œä¸ºåç§°ï¼‰
    active_behaviors_updated = Signal(dict)  # å½“å‰æ´»è·ƒè¡Œä¸ºç»Ÿè®¡ï¼ˆè¡Œä¸ºåç§° -> å”¯ä¸€ç›®æ ‡æ•°é‡ï¼‰
    
    # COCO äººä½“ç±»åˆ«ID
    PERSON_CLASS_ID = 0
    
    def __init__(self):
        super().__init__()
        self.running = False
        self.cap = None
        self.model = None
        self.device_model = None
        self.face_cascade = None  # äººè„¸æ£€æµ‹å™¨
        self.profile_cascade = None  # ä¾§è„¸æ£€æµ‹å™¨
        self.confidence_threshold = 0.35
        self.source = 0
        self.device = 'cpu'
        self.session_id = None
        self.save_to_db = True
        self.save_interval = 30  # æ¯30å¸§ä¿å­˜ä¸€æ¬¡
        self.frame_count = 0
        
        # ä½å¤´æ£€æµ‹ç›¸å…³å‚æ•°
        self.head_down_history = {}  # è®°å½•æ¯ä¸ªäººçš„ä½å¤´å†å² {person_id: [is_head_down, ...]}
        self.head_down_confirm_frames = 3  # è¿ç»­Nå¸§ç¡®è®¤æ‰åˆ¤å®šä¸ºä½å¤´
        self.head_down_min_confidence = 0.55  # ä½å¤´æ£€æµ‹æœ€ä½ç½®ä¿¡åº¦
        
        # å»é‡åŠŸèƒ½ç›¸å…³ç»„ä»¶
        self.position_tracker = PositionTracker(iou_threshold=0.5, max_lost_frames=5)
        self.dedup_engine = DeduplicationEngine(default_cooldown=60.0)
        self.enable_deduplication = True  # æ˜¯å¦å¯ç”¨å»é‡
        
        self._load_models()
        self._load_face_detector()
    
    def _load_models(self):
        """åŠ è½½ YOLO æ¨¡å‹"""
        try:
            from ultralytics import YOLO
            import torch
            
            if torch.cuda.is_available():
                self.device = 'cuda:0'
                print(f"ä½¿ç”¨ GPU: {torch.cuda.get_device_name(0)}")
            else:
                self.device = 'cpu'
                print("ä½¿ç”¨ CPU")
            
            model_path = os.path.join(project_root, 'runs/detect/classroom_behavior_4050/weights/best.pt')
            if os.path.exists(model_path):
                self.model = YOLO(model_path)
                self.model.to(self.device)
                print(f"å·²åŠ è½½è¡Œä¸ºæ£€æµ‹æ¨¡å‹: {model_path}")
            
            device_model_paths = [
                os.path.join(project_root, 'yolo11n.pt'),
                os.path.join(project_root, 'yolo11s.pt'),
            ]
            for path in device_model_paths:
                if os.path.exists(path):
                    self.device_model = YOLO(path)
                    self.device_model.to(self.device)
                    print(f"å·²åŠ è½½ç”µå­è®¾å¤‡æ£€æµ‹æ¨¡å‹: {path}")
                    break
                    
        except Exception as e:
            print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            self.error_occurred.emit(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
    
    def _load_face_detector(self):
        """åŠ è½½äººè„¸æ£€æµ‹å™¨ï¼ˆç”¨äºä½å¤´æ£€æµ‹ï¼‰"""
        try:
            cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            self.face_cascade = cv2.CascadeClassifier(cascade_path)
            
            profile_path = cv2.data.haarcascades + 'haarcascade_profileface.xml'
            self.profile_cascade = cv2.CascadeClassifier(profile_path)
            
            print("äººè„¸æ£€æµ‹å™¨åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"åŠ è½½äººè„¸æ£€æµ‹å™¨å¤±è´¥: {e}")
            self.face_cascade = None
            self.profile_cascade = None
    
    def set_source(self, source):
        self.source = source
    
    def set_confidence(self, conf: float):
        self.confidence_threshold = conf
    
    def set_save_to_db(self, save: bool):
        self.save_to_db = save
    
    def create_session(self, class_id: int = None) -> Optional[int]:
        """åˆ›å»ºæ£€æµ‹ä¼šè¯"""
        try:
            response = requests.post(f"{API_BASE_URL}/detection/session/start", json={
                "class_id": class_id,
                "source_type": "pyside6_realtime"
            }, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data.get('success'):
                    self.session_id = data['data']['session_id']
                    print(f"åˆ›å»ºæ£€æµ‹ä¼šè¯: {self.session_id}")
                    return self.session_id
        except Exception as e:
            print(f"åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
        return None
    
    def end_session(self):
        """ç»“æŸæ£€æµ‹ä¼šè¯"""
        if self.session_id:
            try:
                requests.post(f"{API_BASE_URL}/detection/session/end", json={
                    "session_id": self.session_id
                }, timeout=5)
                print(f"ç»“æŸæ£€æµ‹ä¼šè¯: {self.session_id}")
            except Exception as e:
                print(f"ç»“æŸä¼šè¯å¤±è´¥: {e}")
            self.session_id = None
    
    def save_detection_result(self, detections: List[Detection]):
        """ä¿å­˜æ£€æµ‹ç»“æœåˆ°æ•°æ®åº“ï¼ˆå¸¦å»é‡åŠŸèƒ½ï¼‰"""
        if not self.save_to_db or not self.session_id:
            return
        
        try:
            if self.enable_deduplication:
                # å»é‡è¿½è¸ªå·²ç»åœ¨æ¯å¸§æ›´æ–°äº†ï¼Œè¿™é‡Œåªéœ€è¦è·å–éœ€è¦ä¿å­˜çš„è®°å½•
                # æ ¹æ®å½“å‰è¡Œä¸ºçŠ¶æ€ï¼Œç­›é€‰å‡ºéœ€è¦ä¿å­˜çš„æ£€æµ‹ç»“æœ
                records_to_save = self._get_records_to_save(detections)
                
                # åªä¿å­˜éœ€è¦è®°å½•çš„æ£€æµ‹ç»“æœ
                if records_to_save:
                    self._save_to_api(records_to_save)
            else:
                # ä¸å¯ç”¨å»é‡ï¼Œç›´æ¥ä¿å­˜
                self._save_to_api(detections)
                
        except Exception as e:
            print(f"å»é‡å¤„ç†é”™è¯¯ï¼Œå›é€€åˆ°æ— å»é‡æ¨¡å¼: {e}")
            # é”™è¯¯å›é€€ï¼šç›´æ¥ä¿å­˜æ‰€æœ‰æ£€æµ‹ç»“æœ
            try:
                self._save_to_api(detections)
            except Exception as e2:
                print(f"ä¿å­˜æ£€æµ‹ç»“æœå¤±è´¥: {e2}")
    
    def _get_records_to_save(self, detections: List[Detection]) -> List[Detection]:
        """
        è·å–éœ€è¦ä¿å­˜åˆ°æ•°æ®åº“çš„è®°å½•
        åŸºäºå½“å‰çš„è¡Œä¸ºçŠ¶æ€ï¼Œç­›é€‰å‡ºéœ€è¦ä¿å­˜çš„æ£€æµ‹ç»“æœ
        """
        records_to_save = []
        
        # è·å–å½“å‰è¿½è¸ªçš„æ£€æµ‹ç»“æœ
        tracked_detections = self.position_tracker.update(detections)
        
        for track_id, detection in tracked_detections:
            state = self.dedup_engine.behavior_states.get(track_id)
            
            if state is None:
                # æ–°ç›®æ ‡ï¼Œåº”è¯¥ä¿å­˜
                records_to_save.append(detection)
            else:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜ï¼ˆåŸºäºå†·å´æœŸï¼‰
                cooldown = self.dedup_engine.get_cooldown(detection.class_id)
                time_since_record = state.time_since_last_record()
                
                if detection.class_id != state.behavior_class_id:
                    # è¡Œä¸ºå˜åŒ–ï¼Œåº”è¯¥ä¿å­˜
                    records_to_save.append(detection)
                elif time_since_record >= cooldown:
                    # è¶…è¿‡å†·å´æœŸï¼Œåº”è¯¥ä¿å­˜
                    records_to_save.append(detection)
        
        return records_to_save
    
    def _apply_deduplication(self, detections: List[Detection]) -> List[Detection]:
        """
        åº”ç”¨å»é‡é€»è¾‘ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
        """
        return self._get_records_to_save(detections)
    
    def _save_to_api(self, detections: List[Detection]):
        """ä¿å­˜æ£€æµ‹ç»“æœåˆ°API"""
        if not detections:
            return
            
        detection_data = {
            "session_id": self.session_id,
            "detections": [d.to_dict() for d in detections],
            "total_count": len(detections),
            "warning_count": sum(1 for d in detections if d.behavior_type == 'warning'),
            "normal_count": sum(1 for d in detections if d.behavior_type == 'normal'),
            "behavior_summary": {},
            "timestamp": datetime.now().isoformat()
        }
        
        # ç»Ÿè®¡è¡Œä¸º
        for d in detections:
            name = d.class_name_cn
            if 'ä½¿ç”¨ç”µå­è®¾å¤‡' in name:
                name = 'ä½¿ç”¨ç”µå­è®¾å¤‡'
            detection_data["behavior_summary"][name] = detection_data["behavior_summary"].get(name, 0) + 1
        
        requests.post(f"{API_BASE_URL}/detection/save", json=detection_data, timeout=3)
    
    def set_deduplication_enabled(self, enabled: bool):
        """è®¾ç½®æ˜¯å¦å¯ç”¨å»é‡"""
        self.enable_deduplication = enabled
    
    def set_dedup_cooldown(self, cooldown: float):
        """è®¾ç½®å»é‡å†·å´æœŸ"""
        self.dedup_engine.set_default_cooldown(cooldown)
    
    def reset_dedup_stats(self):
        """é‡ç½®å»é‡ç»Ÿè®¡"""
        self.dedup_engine.reset()
        self.position_tracker.reset()
    
    def _update_dedup_tracking(self, detections: List[Detection]):
        """
        æ›´æ–°å»é‡è¿½è¸ªçŠ¶æ€ï¼ˆæ¯å¸§è°ƒç”¨ï¼Œç”¨äºç»Ÿè®¡æ˜¾ç¤ºï¼‰
        ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼Œåªæ›´æ–°è¿½è¸ªçŠ¶æ€å’Œç»Ÿè®¡
        """
        try:
            # ä½¿ç”¨ä½ç½®è¿½è¸ªå™¨æ›´æ–°è¿½è¸ªçŠ¶æ€
            tracked_detections = self.position_tracker.update(detections)
            
            # ç»Ÿè®¡å½“å‰æ´»è·ƒçš„å”¯ä¸€ç›®æ ‡æ•°é‡ï¼ˆæŒ‰è¡Œä¸ºç±»å‹ï¼‰
            active_behavior_counts = {}
            
            for track_id, detection in tracked_detections:
                # åˆ¤æ–­æ˜¯å¦åº”è¯¥è®°å½•ï¼ˆæ›´æ–°ç»Ÿè®¡ï¼‰
                should_record, reason = self.dedup_engine.should_record(track_id, detection)
                
                # æ›´æ–°è¡Œä¸ºçŠ¶æ€
                self.dedup_engine.update_state(track_id, detection, should_record)
                
                # ç»Ÿè®¡å½“å‰æ´»è·ƒçš„è¡Œä¸ºï¼ˆæ¯ä¸ªå”¯ä¸€ç›®æ ‡åªè®¡ä¸€æ¬¡ï¼‰
                behavior_name = detection.class_name_cn
                if 'ä½¿ç”¨ç”µå­è®¾å¤‡' in behavior_name:
                    behavior_name = 'ä½¿ç”¨ç”µå­è®¾å¤‡'
                active_behavior_counts[behavior_name] = active_behavior_counts.get(behavior_name, 0) + 1
            
            # æ¸…ç†ä¸æ´»è·ƒçš„çŠ¶æ€
            active_ids = {t[0] for t in tracked_detections}
            self.dedup_engine.cleanup_stale_states(active_ids)
            
            # å‘é€ç»Ÿè®¡æ›´æ–°ä¿¡å·
            self.dedup_stats_updated.emit(self.dedup_engine.get_stats())
            
            # å‘é€å½“å‰æ´»è·ƒè¡Œä¸ºç»Ÿè®¡
            self.active_behaviors_updated.emit(active_behavior_counts)
            
        except Exception as e:
            print(f"å»é‡è¿½è¸ªæ›´æ–°é”™è¯¯: {e}")
    
    def run(self):
        self.running = True
        self.frame_count = 0
        
        # åˆ›å»ºä¼šè¯
        if self.save_to_db:
            session_id = self.create_session()
            if session_id:
                self.session_created.emit(session_id)
        
        # æ‰“å¼€è§†é¢‘æº
        if isinstance(self.source, str) and os.path.exists(self.source):
            self.cap = cv2.VideoCapture(self.source)
        else:
            self.cap = cv2.VideoCapture(int(self.source) if str(self.source).isdigit() else 0)
        
        if not self.cap.isOpened():
            self.error_occurred.emit("æ— æ³•æ‰“å¼€è§†é¢‘æº")
            return
        
        frame_count = 0
        start_time = datetime.now()
        
        while self.running:
            ret, frame = self.cap.read()
            if not ret:
                if isinstance(self.source, str):
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    continue
                break
            
            detections = self._detect(frame)
            annotated_frame = self._draw_detections(frame, detections)
            self.frame_ready.emit(annotated_frame, detections)
            
            # æ¯å¸§éƒ½æ›´æ–°å»é‡è¿½è¸ªï¼ˆç”¨äºç»Ÿè®¡æ˜¾ç¤ºï¼‰
            self.frame_count += 1
            if self.enable_deduplication and detections:
                self._update_dedup_tracking(detections)
            
            # å®šæœŸä¿å­˜åˆ°æ•°æ®åº“
            if self.save_to_db and self.frame_count % self.save_interval == 0:
                self.save_detection_result(detections)
            
            frame_count += 1
            elapsed = (datetime.now() - start_time).total_seconds()
            if elapsed >= 1.0:
                fps = frame_count / elapsed
                self.fps_updated.emit(fps)
                frame_count = 0
                start_time = datetime.now()
        
        # ç»“æŸä¼šè¯
        if self.save_to_db:
            self.end_session()
        
        if self.cap:
            self.cap.release()
    
    def _detect(self, frame: np.ndarray) -> List[Detection]:
        detections = []
        person_boxes = []  # äººä½“è¾¹ç•Œæ¡†ï¼ˆç”¨äºä½å¤´æ£€æµ‹ï¼‰
        
        if self.model is not None:
            try:
                results = self.model(frame, conf=self.confidence_threshold, iou=0.5, verbose=False)
                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            cls_id = int(box.cls[0])
                            conf = float(box.conf[0])
                            xyxy = box.xyxy[0].tolist()
                            
                            if cls_id in BEHAVIOR_CLASSES:
                                class_info = BEHAVIOR_CLASSES[cls_id]
                                detections.append(Detection(
                                    class_id=cls_id,
                                    class_name=class_info['name'],
                                    class_name_cn=class_info['cn_name'],
                                    confidence=conf,
                                    bbox=xyxy,
                                    behavior_type=class_info['type']
                                ))
            except Exception as e:
                print(f"è¡Œä¸ºæ£€æµ‹é”™è¯¯: {e}")
        
        if self.device_model is not None:
            try:
                results = self.device_model(frame, conf=0.3, iou=0.5, verbose=False)
                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            cls_id = int(box.cls[0])
                            conf = float(box.conf[0])
                            xyxy = box.xyxy[0].tolist()
                            
                            # æ£€æµ‹ç”µå­è®¾å¤‡ - æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰æ£€æµ‹æ¡†é‡å 
                            if cls_id in ELECTRONIC_DEVICE_CLASSES:
                                # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰è¡Œä¸ºæ£€æµ‹æ¡†é‡å 
                                if not self._is_overlapping(xyxy, detections, threshold=0.3):
                                    device_name = ELECTRONIC_DEVICE_CLASSES[cls_id]
                                    detections.append(Detection(
                                        class_id=5,
                                        class_name='using_electronic_devices',
                                        class_name_cn=f'ä½¿ç”¨ç”µå­è®¾å¤‡({device_name})',
                                        confidence=conf,
                                        bbox=xyxy,
                                        behavior_type='warning'
                                    ))
                            
                            # æ£€æµ‹äººä½“ï¼ˆç”¨äºä½å¤´æ£€æµ‹ï¼‰
                            if cls_id == self.PERSON_CLASS_ID and conf > 0.4:
                                person_boxes.append(xyxy)
            except Exception as e:
                print(f"ç”µå­è®¾å¤‡æ£€æµ‹é”™è¯¯: {e}")
        
        # ä½å¤´æ£€æµ‹
        if person_boxes and self.face_cascade is not None:
            head_down_results = self._detect_head_down(frame, person_boxes, detections)
            for hd in head_down_results:
                # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰æ£€æµ‹æ¡†é‡å 
                if not self._is_overlapping(hd['bbox'], detections, threshold=0.3):
                    head_down_class_info = BEHAVIOR_CLASSES[7]  # head_down
                    detections.append(Detection(
                        class_id=7,
                        class_name=head_down_class_info['name'],
                        class_name_cn=head_down_class_info['cn_name'],
                        confidence=hd['confidence'],
                        bbox=hd['bbox'],
                        behavior_type=head_down_class_info['type']
                    ))
        
        # æœ€ç»ˆå»é‡ï¼šç§»é™¤é‡å çš„æ£€æµ‹æ¡†ï¼Œä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„
        detections = self._remove_duplicate_detections(detections)
        
        return detections
    
    def _is_overlapping(self, bbox: List[float], detections: List[Detection], threshold: float = 0.3) -> bool:
        """æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦ä¸å·²æœ‰æ£€æµ‹æ¡†é‡å """
        x1, y1, x2, y2 = bbox
        box_area = (x2 - x1) * (y2 - y1)
        
        for det in detections:
            dx1, dy1, dx2, dy2 = det.bbox
            
            # è®¡ç®—äº¤é›†
            inter_x1 = max(x1, dx1)
            inter_y1 = max(y1, dy1)
            inter_x2 = min(x2, dx2)
            inter_y2 = min(y2, dy2)
            
            if inter_x2 > inter_x1 and inter_y2 > inter_y1:
                inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
                det_area = (dx2 - dx1) * (dy2 - dy1)
                
                # è®¡ç®—IoU
                union_area = box_area + det_area - inter_area
                iou = inter_area / union_area if union_area > 0 else 0
                
                if iou > threshold:
                    return True
        
        return False
    
    def _remove_duplicate_detections(self, detections: List[Detection]) -> List[Detection]:
        """ç§»é™¤é‡å çš„æ£€æµ‹æ¡†ï¼Œä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„"""
        if len(detections) <= 1:
            return detections
        
        # æŒ‰ç½®ä¿¡åº¦é™åºæ’åº
        sorted_dets = sorted(detections, key=lambda x: x.confidence, reverse=True)
        keep = []
        
        for det in sorted_dets:
            # æ£€æŸ¥æ˜¯å¦ä¸å·²ä¿ç•™çš„æ£€æµ‹æ¡†é‡å 
            is_duplicate = False
            for kept in keep:
                x1, y1, x2, y2 = det.bbox
                kx1, ky1, kx2, ky2 = kept.bbox
                
                # è®¡ç®—äº¤é›†
                inter_x1 = max(x1, kx1)
                inter_y1 = max(y1, ky1)
                inter_x2 = min(x2, kx2)
                inter_y2 = min(y2, ky2)
                
                if inter_x2 > inter_x1 and inter_y2 > inter_y1:
                    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
                    det_area = (x2 - x1) * (y2 - y1)
                    kept_area = (kx2 - kx1) * (ky2 - ky1)
                    
                    # è®¡ç®—IoU
                    union_area = det_area + kept_area - inter_area
                    iou = inter_area / union_area if union_area > 0 else 0
                    
                    # å¦‚æœIoU > 0.4ï¼Œè®¤ä¸ºæ˜¯åŒä¸€ä¸ªäººçš„é‡å¤æ£€æµ‹
                    if iou > 0.4:
                        is_duplicate = True
                        break
            
            if not is_duplicate:
                keep.append(det)
        
        return keep
    
    def _detect_head_down(self, image: np.ndarray, person_boxes: List[List[float]], 
                          existing_detections: List[Detection]) -> List[Dict]:
        """
        æ”¹è¿›çš„ä½å¤´æ£€æµ‹ç®—æ³•
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. åªæ£€æµ‹è¿‘è·ç¦»çš„å¤§ç›®æ ‡ï¼ˆé¿å…è¿œå¤„å°ç›®æ ‡è¯¯æ£€ï¼‰
        2. æ£€æµ‹æ•´ä¸ªäººä½“åŒºåŸŸçš„äººè„¸ï¼Œè€Œä¸ä»…ä»…æ˜¯å¤´éƒ¨åŒºåŸŸ
        3. å¦‚æœåœ¨æ•´ä¸ªäººä½“åŒºåŸŸéƒ½æ£€æµ‹ä¸åˆ°äººè„¸ï¼Œæ‰åˆ¤å®šä¸ºä½å¤´
        4. å¢åŠ æ›´å¤šè¿‡æ»¤æ¡ä»¶å‡å°‘è¯¯æ£€
        
        Args:
            image: å›¾åƒ
            person_boxes: äººä½“è¾¹ç•Œæ¡†åˆ—è¡¨
            existing_detections: å·²æœ‰çš„æ£€æµ‹ç»“æœ
            
        Returns:
            ä½å¤´æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        head_down_detections = []
        
        if self.face_cascade is None:
            return head_down_detections
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        h, w = image.shape[:2]
        
        # è·å–å·²æ£€æµ‹åˆ°çš„è¡Œä¸ºåŒºåŸŸï¼ˆæ’é™¤ä½å¤´ï¼‰
        existing_boxes = []
        if existing_detections:
            for det in existing_detections:
                # æ’é™¤å·²æ£€æµ‹åˆ°çš„è¡Œä¸º
                if det.class_id in [0, 2, 3, 4, 5, 6]:
                    existing_boxes.append(det.bbox)
        
        for person_box in person_boxes:
            x1, y1, x2, y2 = [int(v) for v in person_box]
            
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(w, x2)
            y2 = min(h, y2)
            
            if x2 <= x1 or y2 <= y1:
                continue
            
            person_height = y2 - y1
            person_width = x2 - x1
            
            # ä¸¥æ ¼è¿‡æ»¤æ¡ä»¶1ï¼šåªæ£€æµ‹è¶³å¤Ÿå¤§çš„ç›®æ ‡ï¼ˆè¿‘è·ç¦»ï¼‰
            # äººä½“æ¡†å¿…é¡»å å›¾åƒé«˜åº¦çš„30%ä»¥ä¸Š
            if person_height < h * 0.3:
                continue
            
            # ä¸¥æ ¼è¿‡æ»¤æ¡ä»¶2ï¼šäººä½“æ¡†å¿…é¡»è¶³å¤Ÿå¤§ï¼ˆç»å¯¹å°ºå¯¸ï¼‰
            if person_height < 200 or person_width < 100:
                continue
            
            # ä¸¥æ ¼è¿‡æ»¤æ¡ä»¶3ï¼šå®½é«˜æ¯”æ£€æŸ¥
            aspect_ratio = person_width / person_height
            if aspect_ratio > 1.2 or aspect_ratio < 0.25:
                continue
            
            # ä¸¥æ ¼è¿‡æ»¤æ¡ä»¶4ï¼šæ£€æŸ¥æ˜¯å¦ä¸å·²æ£€æµ‹è¡Œä¸ºåŒºåŸŸé‡å 
            skip_person = False
            for eb in existing_boxes:
                ex1, ey1, ex2, ey2 = [int(v) for v in eb]
                inter_x1 = max(x1, ex1)
                inter_y1 = max(y1, ey1)
                inter_x2 = min(x2, ex2)
                inter_y2 = min(y2, ey2)
                
                if inter_x2 > inter_x1 and inter_y2 > inter_y1:
                    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
                    person_area = (x2 - x1) * (y2 - y1)
                    if inter_area / person_area > 0.15:
                        skip_person = True
                        break
            
            if skip_person:
                continue
            
            # åœ¨æ•´ä¸ªäººä½“ä¸ŠåŠéƒ¨åˆ†åŒºåŸŸæ£€æµ‹äººè„¸ï¼ˆæ‰©å¤§æ£€æµ‹èŒƒå›´åˆ°50%ï¼‰
            head_y2 = y1 + int(person_height * 0.5)
            person_region = gray[y1:head_y2, x1:x2]
            
            if person_region.size == 0:
                continue
            
            # ä½¿ç”¨æ›´å®½æ¾çš„å‚æ•°æ£€æµ‹äººè„¸ï¼ˆå‡å°‘æ¼æ£€ï¼‰
            faces = self.face_cascade.detectMultiScale(
                person_region,
                scaleFactor=1.1,
                minNeighbors=3,  # é™ä½ä»¥æé«˜æ£€æµ‹ç‡
                minSize=(20, 20),
                flags=cv2.CASCADE_SCALE_IMAGE
            )
            
            # å¦‚æœæ£€æµ‹åˆ°äººè„¸ï¼Œè¯´æ˜ä¸æ˜¯ä½å¤´
            if len(faces) > 0:
                continue
            
            # å°è¯•æ£€æµ‹ä¾§è„¸
            if self.profile_cascade is not None:
                profiles = self.profile_cascade.detectMultiScale(
                    person_region,
                    scaleFactor=1.1,
                    minNeighbors=3,
                    minSize=(20, 20),
                    flags=cv2.CASCADE_SCALE_IMAGE
                )
                
                if len(profiles) > 0:
                    continue
                
                # ç¿»è½¬æ£€æµ‹å¦ä¸€ä¾§
                flipped = cv2.flip(person_region, 1)
                profiles_flip = self.profile_cascade.detectMultiScale(
                    flipped,
                    scaleFactor=1.1,
                    minNeighbors=3,
                    minSize=(20, 20),
                    flags=cv2.CASCADE_SCALE_IMAGE
                )
                
                if len(profiles_flip) > 0:
                    continue
            
            # æ‰€æœ‰äººè„¸æ£€æµ‹éƒ½å¤±è´¥ï¼Œåˆ¤å®šä¸ºä½å¤´
            # ç½®ä¿¡åº¦åŸºäºäººä½“æ¡†å¤§å°
            confidence = 0.6 + (person_height / h) * 0.2
            confidence = min(0.85, confidence)
            
            head_down_detections.append({
                'bbox': [x1, y1, x2, y1 + int(person_height * 0.45)],
                'confidence': round(confidence, 3),
                'reason': 'no_face_detected'
            })
        
        return head_down_detections
    
    def _draw_detections(self, frame: np.ndarray, detections: List[Detection]) -> np.ndarray:
        for det in detections:
            x1, y1, x2, y2 = [int(v) for v in det.bbox]
            
            if det.class_id in BEHAVIOR_CLASSES:
                color = BEHAVIOR_CLASSES[det.class_id]['color']
            else:
                color = (255, 0, 255)
            
            color_bgr = (color[2], color[1], color[0])
            thickness = 3 if det.behavior_type == 'warning' else 2
            cv2.rectangle(frame, (x1, y1), (x2, y2), color_bgr, thickness)
            
            label = f"{det.class_name_cn} {det.confidence:.2f}"
            (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(frame, (x1, y1 - label_h - 10), (x1 + label_w + 10, y1), color_bgr, -1)
            
            try:
                from PIL import Image, ImageDraw, ImageFont
                pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                draw = ImageDraw.Draw(pil_img)
                
                font = None
                font_paths = [
                    "C:/Windows/Fonts/msyh.ttc",
                    "C:/Windows/Fonts/simhei.ttf",
                    "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",
                ]
                for fp in font_paths:
                    if os.path.exists(fp):
                        font = ImageFont.truetype(fp, 16)
                        break
                
                if font:
                    draw.text((x1 + 5, y1 - label_h - 8), label, fill=(255, 255, 255), font=font)
                    frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                else:
                    cv2.putText(frame, label, (x1 + 5, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            except:
                cv2.putText(frame, label, (x1 + 5, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return frame
    
    def stop(self):
        self.running = False
        self.wait()


class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("è¯¾å ‚è¡Œä¸ºæ™ºèƒ½æ£€æµ‹ç³»ç»Ÿ - PySide6")
        self.setMinimumSize(1200, 800)
        
        self.detection_thread = DetectionThread()
        self.detection_thread.frame_ready.connect(self.update_frame)
        self.detection_thread.fps_updated.connect(self.update_fps)
        self.detection_thread.error_occurred.connect(self.show_error)
        self.detection_thread.session_created.connect(self.on_session_created)
        self.detection_thread.dedup_stats_updated.connect(self.update_dedup_stats)
        self.detection_thread.behavior_recorded.connect(self.on_behavior_recorded)
        self.detection_thread.active_behaviors_updated.connect(self.update_active_behaviors)
        
        self.behavior_stats = {info['cn_name']: 0 for info in BEHAVIOR_CLASSES.values()}
        self.current_session_id = None
        
        self._setup_ui()
        self._apply_style()
    
    def _setup_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        main_layout = QHBoxLayout(central_widget)
        main_layout.setSpacing(10)
        main_layout.setContentsMargins(10, 10, 10, 10)
        
        # å·¦ä¾§ï¼šè§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
        left_panel = QWidget()
        left_layout = QVBoxLayout(left_panel)
        left_layout.setSpacing(10)
        
        self.video_label = QLabel()
        self.video_label.setMinimumSize(800, 600)
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setStyleSheet("""
            QLabel {
                background-color: #1a1a2e;
                border: 2px solid #667eea;
                border-radius: 10px;
            }
        """)
        self.video_label.setText("ç‚¹å‡»ã€Œå¼€å§‹æ£€æµ‹ã€å¯åŠ¨æ‘„åƒå¤´\næˆ–é€‰æ‹©è§†é¢‘æ–‡ä»¶")
        left_layout.addWidget(self.video_label)
        
        # æ§åˆ¶æŒ‰é’®
        control_layout = QHBoxLayout()
        
        self.start_btn = QPushButton("â–¶ å¼€å§‹æ£€æµ‹")
        self.start_btn.clicked.connect(self.start_detection)
        control_layout.addWidget(self.start_btn)
        
        self.stop_btn = QPushButton("â¹ åœæ­¢æ£€æµ‹")
        self.stop_btn.clicked.connect(self.stop_detection)
        self.stop_btn.setEnabled(False)
        control_layout.addWidget(self.stop_btn)
        
        self.file_btn = QPushButton("ğŸ¬ é€‰æ‹©è§†é¢‘")
        self.file_btn.clicked.connect(self.select_video)
        control_layout.addWidget(self.file_btn)
        
        self.image_btn = QPushButton("ğŸ–¼ï¸ æ£€æµ‹å›¾ç‰‡")
        self.image_btn.clicked.connect(self.detect_image)
        control_layout.addWidget(self.image_btn)
        
        self.screenshot_btn = QPushButton("ğŸ“· æˆªå›¾")
        self.screenshot_btn.clicked.connect(self.take_screenshot)
        control_layout.addWidget(self.screenshot_btn)
        
        left_layout.addLayout(control_layout)
        
        # çŠ¶æ€æ 
        status_layout = QHBoxLayout()
        self.fps_label = QLabel("FPS: 0.0")
        self.fps_label.setStyleSheet("color: #67C23A; font-weight: bold;")
        status_layout.addWidget(self.fps_label)
        
        self.status_label = QLabel("çŠ¶æ€: å°±ç»ª")
        status_layout.addWidget(self.status_label)
        
        self.session_label = QLabel("ä¼šè¯: æœªåˆ›å»º")
        self.session_label.setStyleSheet("color: #909399;")
        status_layout.addWidget(self.session_label)
        
        status_layout.addStretch()
        left_layout.addLayout(status_layout)
        
        main_layout.addWidget(left_panel, stretch=3)
        
        # å³ä¾§ï¼šæ§åˆ¶é¢æ¿å’Œç»Ÿè®¡
        right_panel = QWidget()
        right_panel.setMaximumWidth(350)
        right_layout = QVBoxLayout(right_panel)
        right_layout.setSpacing(10)
        
        # è®¾ç½®ç»„
        settings_group = QGroupBox("æ£€æµ‹è®¾ç½®")
        settings_layout = QVBoxLayout(settings_group)
        
        # æ‘„åƒå¤´é€‰æ‹©
        cam_layout = QHBoxLayout()
        cam_layout.addWidget(QLabel("æ‘„åƒå¤´:"))
        self.camera_combo = QComboBox()
        self.camera_combo.addItems(["æ‘„åƒå¤´ 0", "æ‘„åƒå¤´ 1", "æ‘„åƒå¤´ 2"])
        cam_layout.addWidget(self.camera_combo)
        settings_layout.addLayout(cam_layout)
        
        # ç½®ä¿¡åº¦é˜ˆå€¼
        conf_layout = QHBoxLayout()
        conf_layout.addWidget(QLabel("ç½®ä¿¡åº¦:"))
        self.conf_slider = QSlider(Qt.Horizontal)
        self.conf_slider.setRange(10, 90)
        self.conf_slider.setValue(35)
        self.conf_slider.valueChanged.connect(self.update_confidence)
        conf_layout.addWidget(self.conf_slider)
        self.conf_label = QLabel("0.35")
        conf_layout.addWidget(self.conf_label)
        settings_layout.addLayout(conf_layout)
        
        # ä¿å­˜åˆ°æ•°æ®åº“é€‰é¡¹
        self.save_db_checkbox = QCheckBox("ä¿å­˜æ£€æµ‹ç»“æœåˆ°æ•°æ®åº“")
        self.save_db_checkbox.setChecked(True)
        settings_layout.addWidget(self.save_db_checkbox)
        
        # å»é‡åŠŸèƒ½é€‰é¡¹
        self.dedup_checkbox = QCheckBox("å¯ç”¨è¡Œä¸ºå»é‡")
        self.dedup_checkbox.setChecked(True)
        self.dedup_checkbox.stateChanged.connect(self.update_deduplication)
        settings_layout.addWidget(self.dedup_checkbox)
        
        # å†·å´æœŸé…ç½®
        cooldown_layout = QHBoxLayout()
        cooldown_layout.addWidget(QLabel("å†·å´æœŸ:"))
        self.cooldown_slider = QSlider(Qt.Horizontal)
        self.cooldown_slider.setRange(10, 120)  # 10-120ç§’
        self.cooldown_slider.setValue(60)
        self.cooldown_slider.valueChanged.connect(self.update_cooldown)
        cooldown_layout.addWidget(self.cooldown_slider)
        self.cooldown_label = QLabel("60ç§’")
        cooldown_layout.addWidget(self.cooldown_label)
        settings_layout.addLayout(cooldown_layout)
        
        right_layout.addWidget(settings_group)
        
        # å®æ—¶ç»Ÿè®¡ç»„
        stats_group = QGroupBox("å®æ—¶ç»Ÿè®¡")
        stats_layout = QVBoxLayout(stats_group)
        
        self.stats_table = QTableWidget()
        self.stats_table.setColumnCount(2)
        self.stats_table.setHorizontalHeaderLabels(["è¡Œä¸ºç±»å‹", "æ£€æµ‹æ¬¡æ•°"])
        self.stats_table.horizontalHeader().setSectionResizeMode(QHeaderView.Stretch)
        self.stats_table.setRowCount(len(BEHAVIOR_CLASSES))
        
        for i, (cls_id, info) in enumerate(BEHAVIOR_CLASSES.items()):
            self.stats_table.setItem(i, 0, QTableWidgetItem(info['cn_name']))
            self.stats_table.setItem(i, 1, QTableWidgetItem("0"))
        
        stats_layout.addWidget(self.stats_table)
        
        self.reset_stats_btn = QPushButton("é‡ç½®ç»Ÿè®¡")
        self.reset_stats_btn.clicked.connect(self.reset_stats)
        stats_layout.addWidget(self.reset_stats_btn)
        
        right_layout.addWidget(stats_group)
        
        # å½“å‰æ£€æµ‹ç»“æœ
        current_group = QGroupBox("å½“å‰å¸§æ£€æµ‹")
        current_layout = QVBoxLayout(current_group)
        
        self.current_table = QTableWidget()
        self.current_table.setColumnCount(3)
        self.current_table.setHorizontalHeaderLabels(["è¡Œä¸º", "ç½®ä¿¡åº¦", "ç±»å‹"])
        self.current_table.horizontalHeader().setSectionResizeMode(QHeaderView.Stretch)
        current_layout.addWidget(self.current_table)
        
        right_layout.addWidget(current_group)
        
        # å»é‡ç»Ÿè®¡ç»„
        dedup_group = QGroupBox("å»é‡ç»Ÿè®¡")
        dedup_layout = QVBoxLayout(dedup_group)
        
        # æ£€æµ‹æ¬¡æ•°
        detect_layout = QHBoxLayout()
        detect_layout.addWidget(QLabel("æ£€æµ‹æ¬¡æ•°:"))
        self.detect_count_label = QLabel("0")
        self.detect_count_label.setStyleSheet("font-weight: bold; color: #409EFF;")
        detect_layout.addWidget(self.detect_count_label)
        detect_layout.addStretch()
        dedup_layout.addLayout(detect_layout)
        
        # è®°å½•æ¬¡æ•°
        record_layout = QHBoxLayout()
        record_layout.addWidget(QLabel("è®°å½•æ¬¡æ•°:"))
        self.record_count_label = QLabel("0")
        self.record_count_label.setStyleSheet("font-weight: bold; color: #67C23A;")
        record_layout.addWidget(self.record_count_label)
        record_layout.addStretch()
        dedup_layout.addLayout(record_layout)
        
        # å»é‡ç‡
        rate_layout = QHBoxLayout()
        rate_layout.addWidget(QLabel("å»é‡ç‡:"))
        self.dedup_rate_label = QLabel("0.0%")
        self.dedup_rate_label.setStyleSheet("font-weight: bold; color: #E6A23C;")
        rate_layout.addWidget(self.dedup_rate_label)
        rate_layout.addStretch()
        dedup_layout.addLayout(rate_layout)
        
        right_layout.addWidget(dedup_group)
        
        right_layout.addStretch()
        
        main_layout.addWidget(right_panel, stretch=1)
    
    def _apply_style(self):
        self.setStyleSheet("""
            QMainWindow { background-color: #f5f7fa; }
            QGroupBox {
                font-weight: bold;
                border: 2px solid #667eea;
                border-radius: 8px;
                margin-top: 10px;
                padding-top: 10px;
                background-color: white;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px;
                color: #667eea;
            }
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0, stop:0 #667eea, stop:1 #764ba2);
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 6px;
                font-weight: bold;
            }
            QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0, stop:0 #764ba2, stop:1 #667eea);
            }
            QPushButton:disabled { background: #cccccc; }
            QTableWidget {
                border: 1px solid #e0e0e0;
                border-radius: 4px;
                gridline-color: #f0f0f0;
            }
            QTableWidget::item { padding: 5px; }
            QHeaderView::section {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #667eea, stop:1 #764ba2);
                color: white;
                padding: 8px;
                border: none;
                font-weight: bold;
            }
            QSlider::groove:horizontal {
                height: 8px;
                background: #e0e0e0;
                border-radius: 4px;
            }
            QSlider::handle:horizontal {
                background: #667eea;
                width: 18px;
                margin: -5px 0;
                border-radius: 9px;
            }
            QComboBox {
                padding: 5px 10px;
                border: 1px solid #667eea;
                border-radius: 4px;
            }
        """)
    
    @Slot(np.ndarray, list)
    def update_frame(self, frame: np.ndarray, detections: List[Detection]):
        # è½¬æ¢BGRåˆ°RGBå¹¶ç¡®ä¿å†…å­˜è¿ç»­
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        rgb_frame = np.ascontiguousarray(rgb_frame)
        
        h, w, ch = rgb_frame.shape
        bytes_per_line = ch * w
        
        # ä½¿ç”¨RGBæ ¼å¼åˆ›å»ºQImage
        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
        
        # å¤åˆ¶å›¾åƒæ•°æ®é¿å…å†…å­˜é—®é¢˜
        pixmap = QPixmap.fromImage(qt_image.copy())
        
        scaled_pixmap = pixmap.scaled(
            self.video_label.size(),
            Qt.KeepAspectRatio,
            Qt.SmoothTransformation
        )
        self.video_label.setPixmap(scaled_pixmap)
        
        # æ³¨æ„ï¼šbehavior_stats ç°åœ¨ç”± update_active_behaviors æ›´æ–°
        # æ˜¾ç¤ºå½“å‰æ´»è·ƒçš„å”¯ä¸€ç›®æ ‡æ•°é‡ï¼Œè€Œä¸æ˜¯ç´¯è®¡æ¬¡æ•°
        
        self.current_table.setRowCount(len(detections))
        for i, det in enumerate(detections):
            self.current_table.setItem(i, 0, QTableWidgetItem(det.class_name_cn))
            self.current_table.setItem(i, 1, QTableWidgetItem(f"{det.confidence:.2f}"))
            
            type_item = QTableWidgetItem("âš ï¸ é¢„è­¦" if det.behavior_type == 'warning' else "âœ… æ­£å¸¸")
            if det.behavior_type == 'warning':
                type_item.setForeground(QColor("#F56C6C"))
            else:
                type_item.setForeground(QColor("#67C23A"))
            self.current_table.setItem(i, 2, type_item)
    
    @Slot(float)
    def update_fps(self, fps: float):
        self.fps_label.setText(f"FPS: {fps:.1f}")
    
    @Slot(str)
    def show_error(self, error: str):
        QMessageBox.critical(self, "é”™è¯¯", error)
    
    @Slot(int)
    def on_session_created(self, session_id: int):
        self.current_session_id = session_id
        self.session_label.setText(f"ä¼šè¯: #{session_id}")
        self.session_label.setStyleSheet("color: #67C23A; font-weight: bold;")
    
    def update_confidence(self, value: int):
        conf = value / 100.0
        self.conf_label.setText(f"{conf:.2f}")
        self.detection_thread.set_confidence(conf)
    
    def update_deduplication(self, state: int):
        """æ›´æ–°å»é‡åŠŸèƒ½å¼€å…³"""
        enabled = state == Qt.Checked
        self.detection_thread.set_deduplication_enabled(enabled)
        self.cooldown_slider.setEnabled(enabled)
    
    def update_cooldown(self, value: int):
        """æ›´æ–°å†·å´æœŸè®¾ç½®"""
        self.cooldown_label.setText(f"{value}ç§’")
        self.detection_thread.set_dedup_cooldown(float(value))
    
    @Slot(object)
    def update_dedup_stats(self, stats: DeduplicationStats):
        """æ›´æ–°å»é‡ç»Ÿè®¡æ˜¾ç¤º"""
        self.detect_count_label.setText(str(stats.total_detections))
        self.record_count_label.setText(str(stats.recorded_count))
        self.dedup_rate_label.setText(f"{stats.dedup_rate * 100:.1f}%")
    
    @Slot(str)
    def on_behavior_recorded(self, behavior_name: str):
        """å½“è¡Œä¸ºè¢«è®°å½•æ—¶æ›´æ–°ç»Ÿè®¡ï¼ˆå»é‡åçš„è®¡æ•°ï¼‰- å·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§"""
        pass  # ä¸å†ä½¿ç”¨ç´¯è®¡è®¡æ•°ï¼Œæ”¹ç”¨ update_active_behaviors
    
    @Slot(dict)
    def update_active_behaviors(self, active_counts: dict):
        """æ›´æ–°å½“å‰æ´»è·ƒè¡Œä¸ºç»Ÿè®¡ï¼ˆæ˜¾ç¤ºå½“å‰æœ‰å¤šå°‘ä¸ªå”¯ä¸€ç›®æ ‡ï¼‰"""
        # é‡ç½®æ‰€æœ‰è®¡æ•°ä¸º0
        for key in self.behavior_stats:
            self.behavior_stats[key] = 0
        
        # æ›´æ–°å½“å‰æ´»è·ƒçš„è¡Œä¸ºè®¡æ•°
        for behavior_name, count in active_counts.items():
            if behavior_name in self.behavior_stats:
                self.behavior_stats[behavior_name] = count
        
        # æ›´æ–°ç»Ÿè®¡è¡¨æ ¼æ˜¾ç¤º
        for i, (cls_id, info) in enumerate(BEHAVIOR_CLASSES.items()):
            count = self.behavior_stats.get(info['cn_name'], 0)
            self.stats_table.setItem(i, 1, QTableWidgetItem(str(count)))
    
    def start_detection(self):
        source = self.camera_combo.currentIndex()
        self.detection_thread.set_source(source)
        self.detection_thread.set_save_to_db(self.save_db_checkbox.isChecked())
        self.detection_thread.start()
        
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        self.status_label.setText("çŠ¶æ€: æ£€æµ‹ä¸­...")
    
    def stop_detection(self):
        self.detection_thread.stop()
        
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.status_label.setText("çŠ¶æ€: å·²åœæ­¢")
        self.session_label.setText("ä¼šè¯: å·²ç»“æŸ")
        self.session_label.setStyleSheet("color: #909399;")
    
    def select_video(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "",
            "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mkv *.mov);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        if file_path:
            self.detection_thread.set_source(file_path)
            self.status_label.setText(f"å·²é€‰æ‹©: {os.path.basename(file_path)}")
    
    def detect_image(self):
        """æ£€æµ‹å•å¼ å›¾ç‰‡"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶", "",
            "å›¾ç‰‡æ–‡ä»¶ (*.jpg *.jpeg *.png *.bmp *.webp);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
        )
        if not file_path:
            return
        
        # åœæ­¢è§†é¢‘æ£€æµ‹ï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰
        if self.detection_thread.running:
            self.stop_detection()
        
        self.status_label.setText(f"æ­£åœ¨æ£€æµ‹: {os.path.basename(file_path)}")
        
        try:
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(file_path)
            if image is None:
                QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶")
                return
            
            # ä½¿ç”¨æ£€æµ‹çº¿ç¨‹çš„æ–¹æ³•è¿›è¡Œæ£€æµ‹
            detections = self._detect_single_image(image)
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            annotated_image = self.detection_thread._draw_detections(image.copy(), detections)
            
            # è½¬æ¢ä¸ºRGBæ ¼å¼å¹¶åˆ›å»ºQImage
            # ä½¿ç”¨ .copy() ç¡®ä¿æ•°æ®è¿ç»­ï¼Œé¿å…å†…å­˜é—®é¢˜
            rgb_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
            rgb_image = np.ascontiguousarray(rgb_image)
            
            h, w, ch = rgb_image.shape
            bytes_per_line = ch * w
            
            # åˆ›å»ºQImageæ—¶ä½¿ç”¨RGBæ ¼å¼
            qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)
            
            # ç«‹å³è½¬æ¢ä¸ºQPixmapï¼ˆè¿™ä¼šå¤åˆ¶æ•°æ®ï¼Œé¿å…å†…å­˜é—®é¢˜ï¼‰
            pixmap = QPixmap.fromImage(qt_image.copy())
            
            scaled_pixmap = pixmap.scaled(
                self.video_label.size(),
                Qt.KeepAspectRatio,
                Qt.SmoothTransformation
            )
            self.video_label.setPixmap(scaled_pixmap)
            
            # æ›´æ–°ç»Ÿè®¡
            for det in detections:
                if det.class_name_cn in self.behavior_stats:
                    self.behavior_stats[det.class_name_cn] += 1
                elif 'ä½¿ç”¨ç”µå­è®¾å¤‡' in det.class_name_cn:
                    self.behavior_stats['ä½¿ç”¨ç”µå­è®¾å¤‡'] += 1
            
            for i, (cls_id, info) in enumerate(BEHAVIOR_CLASSES.items()):
                count = self.behavior_stats.get(info['cn_name'], 0)
                self.stats_table.setItem(i, 1, QTableWidgetItem(str(count)))
            
            # æ›´æ–°å½“å‰æ£€æµ‹è¡¨
            self.current_table.setRowCount(len(detections))
            for i, det in enumerate(detections):
                self.current_table.setItem(i, 0, QTableWidgetItem(det.class_name_cn))
                self.current_table.setItem(i, 1, QTableWidgetItem(f"{det.confidence:.2f}"))
                
                type_item = QTableWidgetItem("âš ï¸ é¢„è­¦" if det.behavior_type == 'warning' else "âœ… æ­£å¸¸")
                if det.behavior_type == 'warning':
                    type_item.setForeground(QColor("#F56C6C"))
                else:
                    type_item.setForeground(QColor("#67C23A"))
                self.current_table.setItem(i, 2, type_item)
            
            self.status_label.setText(f"æ£€æµ‹å®Œæˆ: å‘ç° {len(detections)} ä¸ªè¡Œä¸º")
            self.fps_label.setText("FPS: -")
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            QMessageBox.critical(self, "æ£€æµ‹é”™è¯¯", f"æ£€æµ‹å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")
            self.status_label.setText("çŠ¶æ€: æ£€æµ‹å¤±è´¥")
    
    def _detect_single_image(self, frame: np.ndarray) -> List[Detection]:
        """æ£€æµ‹å•å¼ å›¾ç‰‡ï¼ˆå¤ç”¨æ£€æµ‹çº¿ç¨‹çš„é€»è¾‘ï¼‰"""
        detections = []
        person_boxes = []
        
        # è¡Œä¸ºæ£€æµ‹
        if self.detection_thread.model is not None:
            try:
                results = self.detection_thread.model(
                    frame, 
                    conf=self.detection_thread.confidence_threshold, 
                    iou=0.5, 
                    verbose=False
                )
                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            cls_id = int(box.cls[0])
                            conf = float(box.conf[0])
                            xyxy = box.xyxy[0].tolist()
                            
                            if cls_id in BEHAVIOR_CLASSES:
                                class_info = BEHAVIOR_CLASSES[cls_id]
                                detections.append(Detection(
                                    class_id=cls_id,
                                    class_name=class_info['name'],
                                    class_name_cn=class_info['cn_name'],
                                    confidence=conf,
                                    bbox=xyxy,
                                    behavior_type=class_info['type']
                                ))
            except Exception as e:
                print(f"è¡Œä¸ºæ£€æµ‹é”™è¯¯: {e}")
        
        # ç”µå­è®¾å¤‡æ£€æµ‹
        if self.detection_thread.device_model is not None:
            try:
                results = self.detection_thread.device_model(frame, conf=0.3, iou=0.5, verbose=False)
                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            cls_id = int(box.cls[0])
                            conf = float(box.conf[0])
                            xyxy = box.xyxy[0].tolist()
                            
                            if cls_id in ELECTRONIC_DEVICE_CLASSES:
                                if not self.detection_thread._is_overlapping(xyxy, detections, threshold=0.3):
                                    device_name = ELECTRONIC_DEVICE_CLASSES[cls_id]
                                    detections.append(Detection(
                                        class_id=5,
                                        class_name='using_electronic_devices',
                                        class_name_cn=f'ä½¿ç”¨ç”µå­è®¾å¤‡({device_name})',
                                        confidence=conf,
                                        bbox=xyxy,
                                        behavior_type='warning'
                                    ))
                            
                            if cls_id == self.detection_thread.PERSON_CLASS_ID and conf > 0.4:
                                person_boxes.append(xyxy)
            except Exception as e:
                print(f"ç”µå­è®¾å¤‡æ£€æµ‹é”™è¯¯: {e}")
        
        # ä½å¤´æ£€æµ‹
        if person_boxes and self.detection_thread.face_cascade is not None:
            head_down_results = self.detection_thread._detect_head_down(frame, person_boxes, detections)
            for hd in head_down_results:
                if not self.detection_thread._is_overlapping(hd['bbox'], detections, threshold=0.3):
                    head_down_class_info = BEHAVIOR_CLASSES[7]
                    detections.append(Detection(
                        class_id=7,
                        class_name=head_down_class_info['name'],
                        class_name_cn=head_down_class_info['cn_name'],
                        confidence=hd['confidence'],
                        bbox=hd['bbox'],
                        behavior_type=head_down_class_info['type']
                    ))
        
        # å»é‡
        detections = self.detection_thread._remove_duplicate_detections(detections)
        
        return detections
    
    def take_screenshot(self):
        pixmap = self.video_label.pixmap()
        if pixmap:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"screenshot_{timestamp}.png"
            pixmap.save(filename)
            QMessageBox.information(self, "æˆªå›¾æˆåŠŸ", f"å·²ä¿å­˜: {filename}")
    
    def reset_stats(self):
        self.behavior_stats = {info['cn_name']: 0 for info in BEHAVIOR_CLASSES.values()}
        for i in range(self.stats_table.rowCount()):
            self.stats_table.setItem(i, 1, QTableWidgetItem("0"))
        
        # é‡ç½®å»é‡ç»Ÿè®¡
        self.detection_thread.reset_dedup_stats()
        self.detect_count_label.setText("0")
        self.record_count_label.setText("0")
        self.dedup_rate_label.setText("0.0%")
    
    def closeEvent(self, event):
        self.detection_thread.stop()
        event.accept()


def main():
    app = QApplication(sys.argv)
    app.setStyle('Fusion')
    
    window = MainWindow()
    window.show()
    
    sys.exit(app.exec())


if __name__ == '__main__':
    main()